{"ast":null,"code":"var __extends = this && this.__extends || function () {\n  var extendStatics = function (d, b) {\n    extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p];\n    };\n    return extendStatics(d, b);\n  };\n  return function (d, b) {\n    extendStatics(d, b);\n    function __() {\n      this.constructor = d;\n    }\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\nvar __assign = this && this.__assign || function () {\n  __assign = Object.assign || function (t) {\n    for (var s, i = 1, n = arguments.length; i < n; i++) {\n      s = arguments[i];\n      for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\n    }\n    return t;\n  };\n  return __assign.apply(this, arguments);\n};\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  function adopt(value) {\n    return value instanceof P ? value : new P(function (resolve) {\n      resolve(value);\n    });\n  }\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n    function step(result) {\n      result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);\n    }\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\nvar __generator = this && this.__generator || function (thisArg, body) {\n  var _ = {\n      label: 0,\n      sent: function () {\n        if (t[0] & 1) throw t[1];\n        return t[1];\n      },\n      trys: [],\n      ops: []\n    },\n    f,\n    y,\n    t,\n    g;\n  return g = {\n    next: verb(0),\n    \"throw\": verb(1),\n    \"return\": verb(2)\n  }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function () {\n    return this;\n  }), g;\n  function verb(n) {\n    return function (v) {\n      return step([n, v]);\n    };\n  }\n  function step(op) {\n    if (f) throw new TypeError(\"Generator is already executing.\");\n    while (_) try {\n      if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n      if (y = 0, t) op = [op[0] & 2, t.value];\n      switch (op[0]) {\n        case 0:\n        case 1:\n          t = op;\n          break;\n        case 4:\n          _.label++;\n          return {\n            value: op[1],\n            done: false\n          };\n        case 5:\n          _.label++;\n          y = op[1];\n          op = [0];\n          continue;\n        case 7:\n          op = _.ops.pop();\n          _.trys.pop();\n          continue;\n        default:\n          if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {\n            _ = 0;\n            continue;\n          }\n          if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {\n            _.label = op[1];\n            break;\n          }\n          if (op[0] === 6 && _.label < t[1]) {\n            _.label = t[1];\n            t = op;\n            break;\n          }\n          if (t && _.label < t[2]) {\n            _.label = t[2];\n            _.ops.push(op);\n            break;\n          }\n          if (t[2]) _.ops.pop();\n          _.trys.pop();\n          continue;\n      }\n      op = body.call(thisArg, _);\n    } catch (e) {\n      op = [6, e];\n      y = 0;\n    } finally {\n      f = t = 0;\n    }\n    if (op[0] & 5) throw op[1];\n    return {\n      value: op[0] ? op[1] : void 0,\n      done: true\n    };\n  }\n};\nimport { Credentials } from '@aws-amplify/core';\nimport Storage from '@aws-amplify/storage';\nimport { AbstractIdentifyPredictionsProvider } from '../types/Providers';\nimport * as Rekognition from 'aws-sdk/clients/rekognition';\nimport { isStorageSource, isFileSource, isBytesSource, isIdentifyCelebrities, isIdentifyFromCollection } from '../types';\nimport * as Textract from 'aws-sdk/clients/textract';\nimport { makeCamelCase, makeCamelCaseArray, blobToArrayBuffer } from './Utils';\nimport { categorizeRekognitionBlocks, categorizeTextractBlocks } from './IdentifyTextUtils';\nvar AmazonAIIdentifyPredictionsProvider = /** @class */function (_super) {\n  __extends(AmazonAIIdentifyPredictionsProvider, _super);\n  function AmazonAIIdentifyPredictionsProvider() {\n    return _super.call(this) || this;\n  }\n  AmazonAIIdentifyPredictionsProvider.prototype.getProviderName = function () {\n    return 'AmazonAIIdentifyPredictionsProvider';\n  };\n  /**\n   * Verify user input source and converts it into source object readable by Rekognition and Textract.\n   * Note that Rekognition and Textract use the same source interface, so we need not worry about types.\n   * @param {IdentifySource} source - User input source that directs to the object user wants\n   * to identify (storage, file, or bytes).\n   * @return {Promise<Rekognition.Image>} - Promise resolving to the converted source object.\n   */\n  AmazonAIIdentifyPredictionsProvider.prototype.configureSource = function (source) {\n    return new Promise(function (res, rej) {\n      if (isStorageSource(source)) {\n        var storageConfig = {\n          level: source.level,\n          identityId: source.identityId\n        };\n        Storage.get(source.key, storageConfig).then(function (url) {\n          var parser = /https:\\/\\/([a-zA-Z0-9%-_.]+)\\.s3\\.[A-Za-z0-9%-._~]+\\/([a-zA-Z0-9%-._~/]+)\\?/;\n          var parsedURL = url.match(parser);\n          if (parsedURL.length < 3) rej('Invalid S3 key was given.');\n          res({\n            S3Object: {\n              Bucket: parsedURL[1],\n              Name: parsedURL[2]\n            }\n          });\n        }).catch(function (err) {\n          return rej(err);\n        });\n      } else if (isFileSource(source)) {\n        blobToArrayBuffer(source.file).then(function (buffer) {\n          res({\n            Bytes: buffer\n          });\n        }).catch(function (err) {\n          return rej(err);\n        });\n      } else if (isBytesSource(source)) {\n        var bytes = source.bytes;\n        if (bytes instanceof Blob) {\n          blobToArrayBuffer(bytes).then(function (buffer) {\n            res({\n              Bytes: buffer\n            });\n          }).catch(function (err) {\n            return rej(err);\n          });\n        }\n        // everything else can be directly passed to Rekognition / Textract.\n        res({\n          Bytes: bytes\n        });\n      } else {\n        rej('Input source is not configured correctly.');\n      }\n    });\n  };\n  /**\n   * Recognize text from real-world images and documents (plain text, forms and tables). Detects text in the input\n   * image and converts it into machine-readable text.\n   * @param {IdentifySource} source - Object containing the source image and feature types to analyze.\n   * @return {Promise<IdentifyTextOutput>} - Promise resolving to object containing identified texts.\n   */\n  AmazonAIIdentifyPredictionsProvider.prototype.identifyText = function (input) {\n    var _this = this;\n    return new Promise(function (res, rej) {\n      return __awaiter(_this, void 0, void 0, function () {\n        var credentials, _a, _b, _c, region, _d, _e, configFormat, inputDocument, format, featureTypes, textractParam_1, rekognitionParam, param;\n        var _this = this;\n        return __generator(this, function (_f) {\n          switch (_f.label) {\n            case 0:\n              return [4 /*yield*/, Credentials.get()];\n            case 1:\n              credentials = _f.sent();\n              if (!credentials) return [2 /*return*/, rej('No credentials')];\n              _a = this._config.identifyText, _b = _a === void 0 ? {} : _a, _c = _b.region, region = _c === void 0 ? '' : _c, _d = _b.defaults, _e = (_d === void 0 ? {} : _d).format, configFormat = _e === void 0 ? 'PLAIN' : _e;\n              this.rekognition = new Rekognition({\n                region: region,\n                credentials: credentials\n              });\n              this.textract = new Textract({\n                region: region,\n                credentials: credentials\n              });\n              return [4 /*yield*/, this.configureSource(input.text.source).then(function (data) {\n                return inputDocument = data;\n              }).catch(function (err) {\n                rej(err);\n              })];\n            case 2:\n              _f.sent();\n              format = input.text.format || configFormat;\n              featureTypes = [];\n              if (format === 'FORM' || format === 'ALL') featureTypes.push('FORMS');\n              if (format === 'TABLE' || format === 'ALL') featureTypes.push('TABLES');\n              if (featureTypes.length === 0) {\n                textractParam_1 = {\n                  Document: inputDocument\n                };\n                rekognitionParam = {\n                  Image: inputDocument\n                };\n                this.rekognition.detectText(rekognitionParam, function (rekognitionErr, rekognitionData) {\n                  if (rekognitionErr) return rej(rekognitionErr);\n                  var rekognitionResponse = categorizeRekognitionBlocks(rekognitionData.TextDetections);\n                  if (rekognitionResponse.text.words.length < 50) {\n                    // did not hit the word limit, return the data\n                    return res(rekognitionResponse);\n                  }\n                  _this.textract.detectDocumentText(textractParam_1, function (textractErr, textractData) {\n                    if (textractErr) return rej(textractErr);\n                    // use the service that identified more texts.\n                    if (rekognitionData.TextDetections.length > textractData.Blocks.length) {\n                      return res(rekognitionResponse);\n                    } else {\n                      return res(categorizeTextractBlocks(textractData.Blocks));\n                    }\n                  });\n                });\n              } else {\n                param = {\n                  Document: inputDocument,\n                  FeatureTypes: featureTypes\n                };\n                this.textract.analyzeDocument(param, function (err, data) {\n                  if (err) return rej(err);\n                  var blocks = data.Blocks;\n                  res(categorizeTextractBlocks(blocks));\n                });\n              }\n              return [2 /*return*/];\n          }\n        });\n      });\n    });\n  };\n  /**\n   * Identify instances of real world entities from an image and if it contains unsafe content.\n   * @param {IdentifyLabelsInput} input - Object containing the source image and entity type to identify.\n   * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to an array of identified entities.\n   */\n  AmazonAIIdentifyPredictionsProvider.prototype.identifyLabels = function (input) {\n    var _this = this;\n    return new Promise(function (res, rej) {\n      return __awaiter(_this, void 0, void 0, function () {\n        var credentials, _a, _b, _c, region, _d, _e, type, inputImage, param, servicePromises, entityType;\n        return __generator(this, function (_f) {\n          switch (_f.label) {\n            case 0:\n              return [4 /*yield*/, Credentials.get()];\n            case 1:\n              credentials = _f.sent();\n              if (!credentials) return [2 /*return*/, rej('No credentials')];\n              _a = this._config.identifyLabels, _b = _a === void 0 ? {} : _a, _c = _b.region, region = _c === void 0 ? '' : _c, _d = _b.defaults, _e = (_d === void 0 ? {} : _d).type, type = _e === void 0 ? 'LABELS' : _e;\n              this.rekognition = new Rekognition({\n                region: region,\n                credentials: credentials\n              });\n              return [4 /*yield*/, this.configureSource(input.labels.source).then(function (data) {\n                inputImage = data;\n              }).catch(function (err) {\n                return rej(err);\n              })];\n            case 2:\n              _f.sent();\n              param = {\n                Image: inputImage\n              };\n              servicePromises = [];\n              entityType = input.labels.type || type;\n              if (entityType === 'LABELS' || entityType === 'ALL') {\n                servicePromises.push(this.detectLabels(param));\n              }\n              if (entityType === 'UNSAFE' || entityType === 'ALL') {\n                servicePromises.push(this.detectModerationLabels(param));\n              }\n              // if (servicePromises.length === 0) {\n              //     rej('You must specify entity type: LABELS | UNSAFE | ALL');\n              // }\n              Promise.all(servicePromises).then(function (data) {\n                var identifyResult = {};\n                // concatenate resolved promises to a single object\n                data.forEach(function (val) {\n                  identifyResult = __assign(__assign({}, identifyResult), val);\n                });\n                res(identifyResult);\n              }).catch(function (err) {\n                return rej(err);\n              });\n              return [2 /*return*/];\n          }\n        });\n      });\n    });\n  };\n  /**\n   * Calls Rekognition.detectLabels and organizes the returned data.\n   * @param {Rekognition.DetectLabelsRequest} param - parameter to be passed onto Rekognition\n   * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to organized detectLabels response.\n   */\n  AmazonAIIdentifyPredictionsProvider.prototype.detectLabels = function (param) {\n    var _this = this;\n    return new Promise(function (res, rej) {\n      _this.rekognition.detectLabels(param, function (err, data) {\n        if (err) return rej(err);\n        if (!data.Labels) return res({\n          labels: null\n        }); // no image was detected\n        var detectLabelData = data.Labels.map(function (val) {\n          var boxes = val.Instances ? val.Instances.map(function (val) {\n            return makeCamelCase(val.BoundingBox);\n          }) : undefined;\n          return {\n            name: val.Name,\n            boundingBoxes: boxes,\n            metadata: {\n              confidence: val.Confidence,\n              parents: makeCamelCaseArray(val.Parents)\n            }\n          };\n        });\n        return res({\n          labels: detectLabelData\n        });\n      });\n    });\n  };\n  /**\n   * Calls Rekognition.detectModerationLabels and organizes the returned data.\n   * @param {Rekognition.DetectLabelsRequest} param - Parameter to be passed onto Rekognition\n   * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to organized detectModerationLabels response.\n   */\n  AmazonAIIdentifyPredictionsProvider.prototype.detectModerationLabels = function (param) {\n    var _this = this;\n    return new Promise(function (res, rej) {\n      _this.rekognition.detectModerationLabels(param, function (err, data) {\n        if (err) return rej(err);\n        if (data.ModerationLabels.length !== 0) {\n          return res({\n            unsafe: 'YES'\n          });\n        } else {\n          return res({\n            unsafe: 'NO'\n          });\n        }\n      });\n    });\n  };\n  /**\n   * Identify faces within an image that is provided as input, and match faces from a collection\n   * or identify celebrities.\n   * @param {IdentifyEntityInput} input - object containing the source image and face match options.\n   * @return {Promise<IdentifyEntityOutput>} Promise resolving to identify results.\n   */\n  AmazonAIIdentifyPredictionsProvider.prototype.identifyEntities = function (input) {\n    var _this = this;\n    return new Promise(function (res, rej) {\n      return __awaiter(_this, void 0, void 0, function () {\n        var credentials, _a, _b, _c, region, _d, celebrityDetectionEnabled, _e, _f, _g, collectionIdConfig, _h, maxFacesConfig, inputImage, param, _j, _k, collectionId, _l, maxFaces, updatedParam;\n        var _this = this;\n        return __generator(this, function (_m) {\n          switch (_m.label) {\n            case 0:\n              return [4 /*yield*/, Credentials.get()];\n            case 1:\n              credentials = _m.sent();\n              if (!credentials) return [2 /*return*/, rej('No credentials')];\n              _a = this._config.identifyEntities, _b = _a === void 0 ? {} : _a, _c = _b.region, region = _c === void 0 ? '' : _c, _d = _b.celebrityDetectionEnabled, celebrityDetectionEnabled = _d === void 0 ? false : _d, _e = _b.defaults, _f = _e === void 0 ? {} : _e, _g = _f.collectionId, collectionIdConfig = _g === void 0 ? '' : _g, _h = _f.maxEntities, maxFacesConfig = _h === void 0 ? 50 : _h;\n              // default arguments\n              this.rekognition = new Rekognition({\n                region: region,\n                credentials: credentials\n              });\n              return [4 /*yield*/, this.configureSource(input.entities.source).then(function (data) {\n                return inputImage = data;\n              }).catch(function (err) {\n                return rej(err);\n              })];\n            case 2:\n              _m.sent();\n              param = {\n                Image: inputImage\n              };\n              if (isIdentifyCelebrities(input.entities) && input.entities.celebrityDetection) {\n                if (!celebrityDetectionEnabled) {\n                  return [2 /*return*/, rej('Error: You have to enable celebrity detection first')];\n                }\n                this.rekognition.recognizeCelebrities(param, function (err, data) {\n                  if (err) return rej(err);\n                  var faces = data.CelebrityFaces.map(function (celebrity) {\n                    return {\n                      boundingBox: makeCamelCase(celebrity.Face.BoundingBox),\n                      landmarks: makeCamelCaseArray(celebrity.Face.Landmarks),\n                      metadata: __assign(__assign({}, makeCamelCase(celebrity, ['Id', 'Name', 'Urls'])), {\n                        pose: makeCamelCase(celebrity.Face.Pose)\n                      })\n                    };\n                  });\n                  res({\n                    entities: faces\n                  });\n                });\n              } else if (isIdentifyFromCollection(input.entities) && input.entities.collection) {\n                _j = input.entities, _k = _j.collectionId, collectionId = _k === void 0 ? collectionIdConfig : _k, _l = _j.maxEntities, maxFaces = _l === void 0 ? maxFacesConfig : _l;\n                updatedParam = __assign(__assign({}, param), {\n                  CollectionId: collectionId,\n                  MaxFaces: maxFaces\n                });\n                this.rekognition.searchFacesByImage(updatedParam, function (err, data) {\n                  if (err) return rej(err);\n                  var faces = data.FaceMatches.map(function (val) {\n                    return {\n                      boundingBox: makeCamelCase(val.Face.BoundingBox),\n                      metadata: {\n                        externalImageId: _this.decodeExternalImageId(val.Face.ExternalImageId),\n                        similarity: val.Similarity\n                      }\n                    };\n                  });\n                  res({\n                    entities: faces\n                  });\n                });\n              } else {\n                this.rekognition.detectFaces(param, function (err, data) {\n                  if (err) return rej(err);\n                  var faces = data.FaceDetails.map(function (detail) {\n                    // face attributes keys we want to extract from Rekognition's response\n                    var attributeKeys = ['Smile', 'Eyeglasses', 'Sunglasses', 'Gender', 'Beard', 'Mustache', 'EyesOpen', 'MouthOpen'];\n                    var faceAttributes = makeCamelCase(detail, attributeKeys);\n                    if (detail.Emotions) {\n                      faceAttributes['emotions'] = detail.Emotions.map(function (emotion) {\n                        return emotion.Type;\n                      });\n                    }\n                    return {\n                      boundingBox: makeCamelCase(detail.BoundingBox),\n                      landmarks: makeCamelCaseArray(detail.Landmarks),\n                      ageRange: makeCamelCase(detail.AgeRange),\n                      attributes: makeCamelCase(detail, attributeKeys),\n                      metadata: {\n                        confidence: detail.Confidence,\n                        pose: makeCamelCase(detail.Pose)\n                      }\n                    };\n                  });\n                  res({\n                    entities: faces\n                  });\n                });\n              }\n              return [2 /*return*/];\n          }\n        });\n      });\n    });\n  };\n\n  AmazonAIIdentifyPredictionsProvider.prototype.decodeExternalImageId = function (externalImageId) {\n    return ('' + externalImageId).replace(/::/g, '/');\n  };\n  return AmazonAIIdentifyPredictionsProvider;\n}(AbstractIdentifyPredictionsProvider);\nexport default AmazonAIIdentifyPredictionsProvider;","map":{"version":3,"names":["Credentials","Storage","AbstractIdentifyPredictionsProvider","Rekognition","isStorageSource","isFileSource","isBytesSource","isIdentifyCelebrities","isIdentifyFromCollection","Textract","makeCamelCase","makeCamelCaseArray","blobToArrayBuffer","categorizeRekognitionBlocks","categorizeTextractBlocks","AmazonAIIdentifyPredictionsProvider","_super","__extends","call","prototype","getProviderName","configureSource","source","Promise","res","rej","storageConfig","level","identityId","get","key","then","url","parser","parsedURL","match","length","S3Object","Bucket","Name","catch","err","file","buffer","Bytes","bytes","Blob","identifyText","input","_this","__awaiter","credentials","_f","sent","_a","_config","_b","_c","region","_d","defaults","_e","format","configFormat","rekognition","textract","text","data","inputDocument","featureTypes","push","textractParam_1","Document","rekognitionParam","Image","detectText","rekognitionErr","rekognitionData","rekognitionResponse","TextDetections","words","detectDocumentText","textractErr","textractData","Blocks","param","FeatureTypes","analyzeDocument","blocks","identifyLabels","type","labels","inputImage","servicePromises","entityType","detectLabels","detectModerationLabels","all","identifyResult","forEach","val","__assign","Labels","detectLabelData","map","boxes","Instances","BoundingBox","undefined","name","boundingBoxes","metadata","confidence","Confidence","parents","Parents","ModerationLabels","unsafe","identifyEntities","_m","celebrityDetectionEnabled","_g","collectionId","collectionIdConfig","_h","maxEntities","maxFacesConfig","entities","celebrityDetection","recognizeCelebrities","faces","CelebrityFaces","celebrity","boundingBox","Face","landmarks","Landmarks","pose","Pose","collection","_j","_k","_l","maxFaces","updatedParam","CollectionId","MaxFaces","searchFacesByImage","FaceMatches","externalImageId","decodeExternalImageId","ExternalImageId","similarity","Similarity","detectFaces","FaceDetails","detail","attributeKeys","faceAttributes","Emotions","emotion","Type","ageRange","AgeRange","attributes","replace"],"sources":["C:\\Study\\6805\\React\\reacthtml\\node_modules\\@aws-amplify\\predictions\\src\\Providers\\AmazonAIIdentifyPredictionsProvider.ts"],"sourcesContent":["import { Credentials, ConsoleLogger as Logger } from '@aws-amplify/core';\nimport Storage from '@aws-amplify/storage';\nimport { AbstractIdentifyPredictionsProvider } from '../types/Providers';\nimport * as Rekognition from 'aws-sdk/clients/rekognition';\nimport {\n\tIdentifyLabelsInput,\n\tIdentifyLabelsOutput,\n\tIdentifySource,\n\tIdentifyEntitiesInput,\n\tIdentifyEntitiesOutput,\n\tisStorageSource,\n\tisFileSource,\n\tisBytesSource,\n\tIdentifyTextInput,\n\tIdentifyTextOutput,\n\tisIdentifyCelebrities,\n\tisIdentifyFromCollection,\n\tIdentifyFromCollection,\n} from '../types';\nimport * as Textract from 'aws-sdk/clients/textract';\nimport { makeCamelCase, makeCamelCaseArray, blobToArrayBuffer } from './Utils';\nimport {\n\tcategorizeRekognitionBlocks,\n\tcategorizeTextractBlocks,\n} from './IdentifyTextUtils';\n\nexport default class AmazonAIIdentifyPredictionsProvider extends AbstractIdentifyPredictionsProvider {\n\tprivate rekognition: Rekognition;\n\tprivate textract: Textract;\n\n\tconstructor() {\n\t\tsuper();\n\t}\n\n\tgetProviderName() {\n\t\treturn 'AmazonAIIdentifyPredictionsProvider';\n\t}\n\n\t/**\n\t * Verify user input source and converts it into source object readable by Rekognition and Textract.\n\t * Note that Rekognition and Textract use the same source interface, so we need not worry about types.\n\t * @param {IdentifySource} source - User input source that directs to the object user wants\n\t * to identify (storage, file, or bytes).\n\t * @return {Promise<Rekognition.Image>} - Promise resolving to the converted source object.\n\t */\n\tprivate configureSource(source: IdentifySource): Promise<Rekognition.Image> {\n\t\treturn new Promise((res, rej) => {\n\t\t\tif (isStorageSource(source)) {\n\t\t\t\tconst storageConfig = {\n\t\t\t\t\tlevel: source.level,\n\t\t\t\t\tidentityId: source.identityId,\n\t\t\t\t};\n\t\t\t\tStorage.get(source.key, storageConfig)\n\t\t\t\t\t.then((url: string) => {\n\t\t\t\t\t\tconst parser = /https:\\/\\/([a-zA-Z0-9%-_.]+)\\.s3\\.[A-Za-z0-9%-._~]+\\/([a-zA-Z0-9%-._~/]+)\\?/;\n\t\t\t\t\t\tconst parsedURL = url.match(parser);\n\t\t\t\t\t\tif (parsedURL.length < 3) rej('Invalid S3 key was given.');\n\t\t\t\t\t\tres({ S3Object: { Bucket: parsedURL[1], Name: parsedURL[2] } });\n\t\t\t\t\t})\n\t\t\t\t\t.catch(err => rej(err));\n\t\t\t} else if (isFileSource(source)) {\n\t\t\t\tblobToArrayBuffer(source.file)\n\t\t\t\t\t.then(buffer => {\n\t\t\t\t\t\tres({ Bytes: buffer });\n\t\t\t\t\t})\n\t\t\t\t\t.catch(err => rej(err));\n\t\t\t} else if (isBytesSource(source)) {\n\t\t\t\tconst bytes = source.bytes;\n\t\t\t\tif (bytes instanceof Blob) {\n\t\t\t\t\tblobToArrayBuffer(bytes)\n\t\t\t\t\t\t.then(buffer => {\n\t\t\t\t\t\t\tres({ Bytes: buffer });\n\t\t\t\t\t\t})\n\t\t\t\t\t\t.catch(err => rej(err));\n\t\t\t\t}\n\t\t\t\t// everything else can be directly passed to Rekognition / Textract.\n\t\t\t\tres({ Bytes: bytes });\n\t\t\t} else {\n\t\t\t\trej('Input source is not configured correctly.');\n\t\t\t}\n\t\t});\n\t}\n\n\t/**\n\t * Recognize text from real-world images and documents (plain text, forms and tables). Detects text in the input\n\t * image and converts it into machine-readable text.\n\t * @param {IdentifySource} source - Object containing the source image and feature types to analyze.\n\t * @return {Promise<IdentifyTextOutput>} - Promise resolving to object containing identified texts.\n\t */\n\tprotected identifyText(\n\t\tinput: IdentifyTextInput\n\t): Promise<IdentifyTextOutput> {\n\t\treturn new Promise(async (res, rej) => {\n\t\t\tconst credentials = await Credentials.get();\n\t\t\tif (!credentials) return rej('No credentials');\n\t\t\tconst {\n\t\t\t\tidentifyText: {\n\t\t\t\t\tregion = '',\n\t\t\t\t\tdefaults: { format: configFormat = 'PLAIN' } = {},\n\t\t\t\t} = {},\n\t\t\t} = this._config;\n\t\t\tthis.rekognition = new Rekognition({ region, credentials });\n\t\t\tthis.textract = new Textract({ region, credentials });\n\t\t\tlet inputDocument: Textract.Document;\n\t\t\tawait this.configureSource(input.text.source)\n\t\t\t\t.then(data => (inputDocument = data))\n\t\t\t\t.catch(err => {\n\t\t\t\t\trej(err);\n\t\t\t\t});\n\n\t\t\t// get default value if format isn't specified in the input.\n\t\t\tconst format = input.text.format || configFormat;\n\t\t\tconst featureTypes: Textract.FeatureTypes = []; // structures we want to analyze (e.g. [TABLES, FORMS]).\n\t\t\tif (format === 'FORM' || format === 'ALL') featureTypes.push('FORMS');\n\t\t\tif (format === 'TABLE' || format === 'ALL') featureTypes.push('TABLES');\n\t\t\tif (featureTypes.length === 0) {\n\t\t\t\t/**\n\t\t\t\t * Empty featureTypes indicates that we will identify plain text. We will use rekognition (suitable\n\t\t\t\t * for everyday images but has 50 word limit) first and see if reaches its word limit. If it does, then\n\t\t\t\t * we call textract and use the data that identify more words.\n\t\t\t\t */\n\t\t\t\tconst textractParam: Textract.DetectDocumentTextRequest = {\n\t\t\t\t\tDocument: inputDocument,\n\t\t\t\t};\n\t\t\t\tconst rekognitionParam: Rekognition.DetectTextRequest = {\n\t\t\t\t\tImage: inputDocument,\n\t\t\t\t};\n\t\t\t\tthis.rekognition.detectText(\n\t\t\t\t\trekognitionParam,\n\t\t\t\t\t(rekognitionErr, rekognitionData) => {\n\t\t\t\t\t\tif (rekognitionErr) return rej(rekognitionErr);\n\t\t\t\t\t\tconst rekognitionResponse = categorizeRekognitionBlocks(\n\t\t\t\t\t\t\trekognitionData.TextDetections\n\t\t\t\t\t\t);\n\t\t\t\t\t\tif (rekognitionResponse.text.words.length < 50) {\n\t\t\t\t\t\t\t// did not hit the word limit, return the data\n\t\t\t\t\t\t\treturn res(rekognitionResponse);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tthis.textract.detectDocumentText(\n\t\t\t\t\t\t\ttextractParam,\n\t\t\t\t\t\t\t(textractErr, textractData) => {\n\t\t\t\t\t\t\t\tif (textractErr) return rej(textractErr);\n\t\t\t\t\t\t\t\t// use the service that identified more texts.\n\t\t\t\t\t\t\t\tif (\n\t\t\t\t\t\t\t\t\trekognitionData.TextDetections.length >\n\t\t\t\t\t\t\t\t\ttextractData.Blocks.length\n\t\t\t\t\t\t\t\t) {\n\t\t\t\t\t\t\t\t\treturn res(rekognitionResponse);\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\treturn res(categorizeTextractBlocks(textractData.Blocks));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t);\n\t\t\t\t\t}\n\t\t\t\t);\n\t\t\t} else {\n\t\t\t\tconst param: Textract.AnalyzeDocumentRequest = {\n\t\t\t\t\tDocument: inputDocument,\n\t\t\t\t\tFeatureTypes: featureTypes,\n\t\t\t\t};\n\t\t\t\tthis.textract.analyzeDocument(param, (err, data) => {\n\t\t\t\t\tif (err) return rej(err);\n\t\t\t\t\tconst blocks = data.Blocks;\n\t\t\t\t\tres(categorizeTextractBlocks(blocks));\n\t\t\t\t});\n\t\t\t}\n\t\t});\n\t}\n\n\t/**\n\t * Identify instances of real world entities from an image and if it contains unsafe content.\n\t * @param {IdentifyLabelsInput} input - Object containing the source image and entity type to identify.\n\t * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to an array of identified entities.\n\t */\n\tprotected identifyLabels(\n\t\tinput: IdentifyLabelsInput\n\t): Promise<IdentifyLabelsOutput> {\n\t\treturn new Promise(async (res, rej) => {\n\t\t\tconst credentials = await Credentials.get();\n\t\t\tif (!credentials) return rej('No credentials');\n\t\t\tconst {\n\t\t\t\tidentifyLabels: {\n\t\t\t\t\tregion = '',\n\t\t\t\t\tdefaults: { type = 'LABELS' } = {},\n\t\t\t\t} = {},\n\t\t\t} = this._config;\n\t\t\tthis.rekognition = new Rekognition({ region, credentials });\n\t\t\tlet inputImage: Rekognition.Image;\n\t\t\tawait this.configureSource(input.labels.source)\n\t\t\t\t.then(data => {\n\t\t\t\t\tinputImage = data;\n\t\t\t\t})\n\t\t\t\t.catch(err => {\n\t\t\t\t\treturn rej(err);\n\t\t\t\t});\n\t\t\tconst param = { Image: inputImage };\n\t\t\tconst servicePromises = [];\n\n\t\t\t// get default argument\n\t\t\tconst entityType = input.labels.type || type;\n\t\t\tif (entityType === 'LABELS' || entityType === 'ALL') {\n\t\t\t\tservicePromises.push(this.detectLabels(param));\n\t\t\t}\n\t\t\tif (entityType === 'UNSAFE' || entityType === 'ALL') {\n\t\t\t\tservicePromises.push(this.detectModerationLabels(param));\n\t\t\t}\n\t\t\t// if (servicePromises.length === 0) {\n\t\t\t//     rej('You must specify entity type: LABELS | UNSAFE | ALL');\n\t\t\t// }\n\t\t\tPromise.all(servicePromises)\n\t\t\t\t.then(data => {\n\t\t\t\t\tlet identifyResult: IdentifyLabelsOutput = {};\n\t\t\t\t\t// concatenate resolved promises to a single object\n\t\t\t\t\tdata.forEach(val => {\n\t\t\t\t\t\tidentifyResult = { ...identifyResult, ...val };\n\t\t\t\t\t});\n\t\t\t\t\tres(identifyResult);\n\t\t\t\t})\n\t\t\t\t.catch(err => rej(err));\n\t\t});\n\t}\n\n\t/**\n\t * Calls Rekognition.detectLabels and organizes the returned data.\n\t * @param {Rekognition.DetectLabelsRequest} param - parameter to be passed onto Rekognition\n\t * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to organized detectLabels response.\n\t */\n\tprivate detectLabels(\n\t\tparam: Rekognition.DetectLabelsRequest\n\t): Promise<IdentifyLabelsOutput> {\n\t\treturn new Promise((res, rej) => {\n\t\t\tthis.rekognition.detectLabels(param, (err, data) => {\n\t\t\t\tif (err) return rej(err);\n\t\t\t\tif (!data.Labels) return res({ labels: null }); // no image was detected\n\t\t\t\tconst detectLabelData = data.Labels.map(val => {\n\t\t\t\t\tconst boxes = val.Instances\n\t\t\t\t\t\t? val.Instances.map(val => makeCamelCase(val.BoundingBox))\n\t\t\t\t\t\t: undefined;\n\t\t\t\t\treturn {\n\t\t\t\t\t\tname: val.Name,\n\t\t\t\t\t\tboundingBoxes: boxes,\n\t\t\t\t\t\tmetadata: {\n\t\t\t\t\t\t\tconfidence: val.Confidence,\n\t\t\t\t\t\t\tparents: makeCamelCaseArray(val.Parents),\n\t\t\t\t\t\t},\n\t\t\t\t\t};\n\t\t\t\t});\n\t\t\t\treturn res({ labels: detectLabelData });\n\t\t\t});\n\t\t});\n\t}\n\n\t/**\n\t * Calls Rekognition.detectModerationLabels and organizes the returned data.\n\t * @param {Rekognition.DetectLabelsRequest} param - Parameter to be passed onto Rekognition\n\t * @return {Promise<IdentifyLabelsOutput>} - Promise resolving to organized detectModerationLabels response.\n\t */\n\tprivate detectModerationLabels(\n\t\tparam: Rekognition.DetectFacesRequest\n\t): Promise<IdentifyLabelsOutput> {\n\t\treturn new Promise((res, rej) => {\n\t\t\tthis.rekognition.detectModerationLabels(param, (err, data) => {\n\t\t\t\tif (err) return rej(err);\n\t\t\t\tif (data.ModerationLabels.length !== 0) {\n\t\t\t\t\treturn res({ unsafe: 'YES' });\n\t\t\t\t} else {\n\t\t\t\t\treturn res({ unsafe: 'NO' });\n\t\t\t\t}\n\t\t\t});\n\t\t});\n\t}\n\n\t/**\n\t * Identify faces within an image that is provided as input, and match faces from a collection\n\t * or identify celebrities.\n\t * @param {IdentifyEntityInput} input - object containing the source image and face match options.\n\t * @return {Promise<IdentifyEntityOutput>} Promise resolving to identify results.\n\t */\n\tprotected identifyEntities(\n\t\tinput: IdentifyEntitiesInput\n\t): Promise<IdentifyEntitiesOutput> {\n\t\treturn new Promise(async (res, rej) => {\n\t\t\tconst credentials = await Credentials.get();\n\t\t\tif (!credentials) return rej('No credentials');\n\t\t\tconst {\n\t\t\t\tidentifyEntities: {\n\t\t\t\t\tregion = '',\n\t\t\t\t\tcelebrityDetectionEnabled = false,\n\t\t\t\t\tdefaults: {\n\t\t\t\t\t\tcollectionId: collectionIdConfig = '',\n\t\t\t\t\t\tmaxEntities: maxFacesConfig = 50,\n\t\t\t\t\t} = {},\n\t\t\t\t} = {},\n\t\t\t} = this._config;\n\t\t\t// default arguments\n\n\t\t\tthis.rekognition = new Rekognition({ region, credentials });\n\t\t\tlet inputImage: Rekognition.Image;\n\t\t\tawait this.configureSource(input.entities.source)\n\t\t\t\t.then(data => (inputImage = data))\n\t\t\t\t.catch(err => {\n\t\t\t\t\treturn rej(err);\n\t\t\t\t});\n\n\t\t\tconst param = { Image: inputImage };\n\n\t\t\tif (\n\t\t\t\tisIdentifyCelebrities(input.entities) &&\n\t\t\t\tinput.entities.celebrityDetection\n\t\t\t) {\n\t\t\t\tif (!celebrityDetectionEnabled) {\n\t\t\t\t\treturn rej('Error: You have to enable celebrity detection first');\n\t\t\t\t}\n\t\t\t\tthis.rekognition.recognizeCelebrities(param, (err, data) => {\n\t\t\t\t\tif (err) return rej(err);\n\t\t\t\t\tconst faces = data.CelebrityFaces.map(celebrity => {\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\tboundingBox: makeCamelCase(celebrity.Face.BoundingBox),\n\t\t\t\t\t\t\tlandmarks: makeCamelCaseArray(celebrity.Face.Landmarks),\n\t\t\t\t\t\t\tmetadata: {\n\t\t\t\t\t\t\t\t...makeCamelCase(celebrity, ['Id', 'Name', 'Urls']),\n\t\t\t\t\t\t\t\tpose: makeCamelCase(celebrity.Face.Pose),\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t};\n\t\t\t\t\t});\n\t\t\t\t\tres({ entities: faces });\n\t\t\t\t});\n\t\t\t} else if (\n\t\t\t\tisIdentifyFromCollection(input.entities) &&\n\t\t\t\tinput.entities.collection\n\t\t\t) {\n\t\t\t\tconst {\n\t\t\t\t\tcollectionId = collectionIdConfig,\n\t\t\t\t\tmaxEntities: maxFaces = maxFacesConfig,\n\t\t\t\t} = input.entities as IdentifyFromCollection;\n\n\t\t\t\t// Concatenate additional parameters\n\t\t\t\tconst updatedParam = {\n\t\t\t\t\t...param,\n\t\t\t\t\tCollectionId: collectionId,\n\t\t\t\t\tMaxFaces: maxFaces,\n\t\t\t\t};\n\t\t\t\tthis.rekognition.searchFacesByImage(updatedParam, (err, data) => {\n\t\t\t\t\tif (err) return rej(err);\n\t\t\t\t\tconst faces = data.FaceMatches.map(val => {\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\tboundingBox: makeCamelCase(val.Face.BoundingBox),\n\t\t\t\t\t\t\tmetadata: {\n\t\t\t\t\t\t\t\texternalImageId: this.decodeExternalImageId(\n\t\t\t\t\t\t\t\t\tval.Face.ExternalImageId\n\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\tsimilarity: val.Similarity,\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t};\n\t\t\t\t\t});\n\t\t\t\t\tres({ entities: faces });\n\t\t\t\t});\n\t\t\t} else {\n\t\t\t\tthis.rekognition.detectFaces(param, (err, data) => {\n\t\t\t\t\tif (err) return rej(err);\n\t\t\t\t\tconst faces = data.FaceDetails.map(detail => {\n\t\t\t\t\t\t// face attributes keys we want to extract from Rekognition's response\n\t\t\t\t\t\tconst attributeKeys = [\n\t\t\t\t\t\t\t'Smile',\n\t\t\t\t\t\t\t'Eyeglasses',\n\t\t\t\t\t\t\t'Sunglasses',\n\t\t\t\t\t\t\t'Gender',\n\t\t\t\t\t\t\t'Beard',\n\t\t\t\t\t\t\t'Mustache',\n\t\t\t\t\t\t\t'EyesOpen',\n\t\t\t\t\t\t\t'MouthOpen',\n\t\t\t\t\t\t];\n\t\t\t\t\t\tconst faceAttributes = makeCamelCase(detail, attributeKeys);\n\t\t\t\t\t\tif (detail.Emotions) {\n\t\t\t\t\t\t\tfaceAttributes['emotions'] = detail.Emotions.map(\n\t\t\t\t\t\t\t\temotion => emotion.Type\n\t\t\t\t\t\t\t);\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\tboundingBox: makeCamelCase(detail.BoundingBox),\n\t\t\t\t\t\t\tlandmarks: makeCamelCaseArray(detail.Landmarks),\n\t\t\t\t\t\t\tageRange: makeCamelCase(detail.AgeRange),\n\t\t\t\t\t\t\tattributes: makeCamelCase(detail, attributeKeys),\n\t\t\t\t\t\t\tmetadata: {\n\t\t\t\t\t\t\t\tconfidence: detail.Confidence,\n\t\t\t\t\t\t\t\tpose: makeCamelCase(detail.Pose),\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t};\n\t\t\t\t\t});\n\t\t\t\t\tres({ entities: faces });\n\t\t\t\t});\n\t\t\t}\n\t\t});\n\t}\n\n\tprivate decodeExternalImageId(externalImageId: string): string {\n\t\treturn ('' + externalImageId).replace(/::/g, '/');\n\t}\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,SAASA,WAAW,QAAiC,mBAAmB;AACxE,OAAOC,OAAO,MAAM,sBAAsB;AAC1C,SAASC,mCAAmC,QAAQ,oBAAoB;AACxE,OAAO,KAAKC,WAAW,MAAM,6BAA6B;AAC1D,SAMCC,eAAe,EACfC,YAAY,EACZC,aAAa,EAGbC,qBAAqB,EACrBC,wBAAwB,QAElB,UAAU;AACjB,OAAO,KAAKC,QAAQ,MAAM,0BAA0B;AACpD,SAASC,aAAa,EAAEC,kBAAkB,EAAEC,iBAAiB,QAAQ,SAAS;AAC9E,SACCC,2BAA2B,EAC3BC,wBAAwB,QAClB,qBAAqB;AAE5B,IAAAC,mCAAA,0BAAAC,MAAA;EAAiEC,SAAA,CAAAF,mCAAA,EAAAC,MAAA;EAIhE,SAAAD,oCAAA;WACCC,MAAA,CAAAE,IAAA,MAAO;EACR;EAEAH,mCAAA,CAAAI,SAAA,CAAAC,eAAe,GAAf;IACC,OAAO,qCAAqC;EAC7C,CAAC;EAED;;;;;;;EAOQL,mCAAA,CAAAI,SAAA,CAAAE,eAAe,GAAvB,UAAwBC,MAAsB;IAC7C,OAAO,IAAIC,OAAO,CAAC,UAACC,GAAG,EAAEC,GAAG;MAC3B,IAAIrB,eAAe,CAACkB,MAAM,CAAC,EAAE;QAC5B,IAAMI,aAAa,GAAG;UACrBC,KAAK,EAAEL,MAAM,CAACK,KAAK;UACnBC,UAAU,EAAEN,MAAM,CAACM;SACnB;QACD3B,OAAO,CAAC4B,GAAG,CAACP,MAAM,CAACQ,GAAG,EAAEJ,aAAa,CAAC,CACpCK,IAAI,CAAC,UAACC,GAAW;UACjB,IAAMC,MAAM,GAAG,6EAA6E;UAC5F,IAAMC,SAAS,GAAGF,GAAG,CAACG,KAAK,CAACF,MAAM,CAAC;UACnC,IAAIC,SAAS,CAACE,MAAM,GAAG,CAAC,EAAEX,GAAG,CAAC,2BAA2B,CAAC;UAC1DD,GAAG,CAAC;YAAEa,QAAQ,EAAE;cAAEC,MAAM,EAAEJ,SAAS,CAAC,CAAC,CAAC;cAAEK,IAAI,EAAEL,SAAS,CAAC,CAAC;YAAC;UAAE,CAAE,CAAC;QAChE,CAAC,CAAC,CACDM,KAAK,CAAC,UAAAC,GAAG;UAAI,OAAAhB,GAAG,CAACgB,GAAG,CAAC;QAAR,CAAQ,CAAC;OACxB,MAAM,IAAIpC,YAAY,CAACiB,MAAM,CAAC,EAAE;QAChCV,iBAAiB,CAACU,MAAM,CAACoB,IAAI,CAAC,CAC5BX,IAAI,CAAC,UAAAY,MAAM;UACXnB,GAAG,CAAC;YAAEoB,KAAK,EAAED;UAAM,CAAE,CAAC;QACvB,CAAC,CAAC,CACDH,KAAK,CAAC,UAAAC,GAAG;UAAI,OAAAhB,GAAG,CAACgB,GAAG,CAAC;QAAR,CAAQ,CAAC;OACxB,MAAM,IAAInC,aAAa,CAACgB,MAAM,CAAC,EAAE;QACjC,IAAMuB,KAAK,GAAGvB,MAAM,CAACuB,KAAK;QAC1B,IAAIA,KAAK,YAAYC,IAAI,EAAE;UAC1BlC,iBAAiB,CAACiC,KAAK,CAAC,CACtBd,IAAI,CAAC,UAAAY,MAAM;YACXnB,GAAG,CAAC;cAAEoB,KAAK,EAAED;YAAM,CAAE,CAAC;UACvB,CAAC,CAAC,CACDH,KAAK,CAAC,UAAAC,GAAG;YAAI,OAAAhB,GAAG,CAACgB,GAAG,CAAC;UAAR,CAAQ,CAAC;;QAEzB;QACAjB,GAAG,CAAC;UAAEoB,KAAK,EAAEC;QAAK,CAAE,CAAC;OACrB,MAAM;QACNpB,GAAG,CAAC,2CAA2C,CAAC;;IAElD,CAAC,CAAC;EACH,CAAC;EAED;;;;;;EAMUV,mCAAA,CAAAI,SAAA,CAAA4B,YAAY,GAAtB,UACCC,KAAwB;IADzB,IAAAC,KAAA;IAGC,OAAO,IAAI1B,OAAO,CAAC,UAAOC,GAAG,EAAEC,GAAG;MAAA,OAAAyB,SAAA,CAAAD,KAAA;;;;;;cACb,qBAAMjD,WAAW,CAAC6B,GAAG,EAAE;;cAArCsB,WAAW,GAAGC,EAAA,CAAAC,IAAA,EAAuB;cAC3C,IAAI,CAACF,WAAW,EAAE,sBAAO1B,GAAG,CAAC,gBAAgB,CAAC;cAE7C6B,EAAA,GAIG,IAAI,CAACC,OAAO,CAAAR,YADT,EAHNS,EAAA,GAAAF,EAAA,cAGI,EAAE,GAAAA,EAAA,EAFLG,EAAA,GAAAD,EAAA,CAAAE,MAAW,EAAXA,MAAM,GAAAD,EAAA,cAAG,EAAE,GAAAA,EAAA,EACXE,EAAA,GAAAH,EAAA,CAAAI,QAAiD,EAArCC,EAAA,IAAAF,EAAA,cAAmC,EAAE,GAAAA,EAAA,EAAAG,MAAP,EAAtBC,YAAY,GAAAF,EAAA,cAAG,OAAO,GAAAA,EAAA;cAG5C,IAAI,CAACG,WAAW,GAAG,IAAI7D,WAAW,CAAC;gBAAEuD,MAAM,EAAAA,MAAA;gBAAEP,WAAW,EAAAA;cAAA,CAAE,CAAC;cAC3D,IAAI,CAACc,QAAQ,GAAG,IAAIxD,QAAQ,CAAC;gBAAEiD,MAAM,EAAAA,MAAA;gBAAEP,WAAW,EAAAA;cAAA,CAAE,CAAC;cAErD,qBAAM,IAAI,CAAC9B,eAAe,CAAC2B,KAAK,CAACkB,IAAI,CAAC5C,MAAM,CAAC,CAC3CS,IAAI,CAAC,UAAAoC,IAAI;gBAAI,OAACC,aAAa,GAAGD,IAAI;cAArB,CAAsB,CAAC,CACpC3B,KAAK,CAAC,UAAAC,GAAG;gBACThB,GAAG,CAACgB,GAAG,CAAC;cACT,CAAC,CAAC;;cAJHW,EAAA,CAAAC,IAAA,EAIG;cAGGS,MAAM,GAAGd,KAAK,CAACkB,IAAI,CAACJ,MAAM,IAAIC,YAAY;cAC1CM,YAAY,GAA0B,EAAE;cAC9C,IAAIP,MAAM,KAAK,MAAM,IAAIA,MAAM,KAAK,KAAK,EAAEO,YAAY,CAACC,IAAI,CAAC,OAAO,CAAC;cACrE,IAAIR,MAAM,KAAK,OAAO,IAAIA,MAAM,KAAK,KAAK,EAAEO,YAAY,CAACC,IAAI,CAAC,QAAQ,CAAC;cACvE,IAAID,YAAY,CAACjC,MAAM,KAAK,CAAC,EAAE;gBAMxBmC,eAAA,GAAoD;kBACzDC,QAAQ,EAAEJ;iBACV;gBACKK,gBAAgB,GAAkC;kBACvDC,KAAK,EAAEN;iBACP;gBACD,IAAI,CAACJ,WAAW,CAACW,UAAU,CAC1BF,gBAAgB,EAChB,UAACG,cAAc,EAAEC,eAAe;kBAC/B,IAAID,cAAc,EAAE,OAAOnD,GAAG,CAACmD,cAAc,CAAC;kBAC9C,IAAME,mBAAmB,GAAGjE,2BAA2B,CACtDgE,eAAe,CAACE,cAAc,CAC9B;kBACD,IAAID,mBAAmB,CAACZ,IAAI,CAACc,KAAK,CAAC5C,MAAM,GAAG,EAAE,EAAE;oBAC/C;oBACA,OAAOZ,GAAG,CAACsD,mBAAmB,CAAC;;kBAEhC7B,KAAI,CAACgB,QAAQ,CAACgB,kBAAkB,CAC/BV,eAAa,EACb,UAACW,WAAW,EAAEC,YAAY;oBACzB,IAAID,WAAW,EAAE,OAAOzD,GAAG,CAACyD,WAAW,CAAC;oBACxC;oBACA,IACCL,eAAe,CAACE,cAAc,CAAC3C,MAAM,GACrC+C,YAAY,CAACC,MAAM,CAAChD,MAAM,EACzB;sBACD,OAAOZ,GAAG,CAACsD,mBAAmB,CAAC;qBAC/B,MAAM;sBACN,OAAOtD,GAAG,CAACV,wBAAwB,CAACqE,YAAY,CAACC,MAAM,CAAC,CAAC;;kBAE3D,CAAC,CACD;gBACF,CAAC,CACD;eACD,MAAM;gBACAC,KAAK,GAAoC;kBAC9Cb,QAAQ,EAAEJ,aAAa;kBACvBkB,YAAY,EAAEjB;iBACd;gBACD,IAAI,CAACJ,QAAQ,CAACsB,eAAe,CAACF,KAAK,EAAE,UAAC5C,GAAG,EAAE0B,IAAI;kBAC9C,IAAI1B,GAAG,EAAE,OAAOhB,GAAG,CAACgB,GAAG,CAAC;kBACxB,IAAM+C,MAAM,GAAGrB,IAAI,CAACiB,MAAM;kBAC1B5D,GAAG,CAACV,wBAAwB,CAAC0E,MAAM,CAAC,CAAC;gBACtC,CAAC,CAAC;;;;;;KAEH,CAAC;EACH,CAAC;EAED;;;;;EAKUzE,mCAAA,CAAAI,SAAA,CAAAsE,cAAc,GAAxB,UACCzC,KAA0B;IAD3B,IAAAC,KAAA;IAGC,OAAO,IAAI1B,OAAO,CAAC,UAAOC,GAAG,EAAEC,GAAG;MAAA,OAAAyB,SAAA,CAAAD,KAAA;;;;;cACb,qBAAMjD,WAAW,CAAC6B,GAAG,EAAE;;cAArCsB,WAAW,GAAGC,EAAA,CAAAC,IAAA,EAAuB;cAC3C,IAAI,CAACF,WAAW,EAAE,sBAAO1B,GAAG,CAAC,gBAAgB,CAAC;cAE7C6B,EAAA,GAIG,IAAI,CAACC,OAAO,CAAAkC,cADT,EAHNjC,EAAA,GAAAF,EAAA,cAGI,EAAE,GAAAA,EAAA,EAFLG,EAAA,GAAAD,EAAA,CAAAE,MAAW,EAAXA,MAAM,GAAAD,EAAA,cAAG,EAAE,GAAAA,EAAA,EACXE,EAAA,GAAAH,EAAA,CAAAI,QAAkC,EAAtBC,EAAA,IAAAF,EAAA,cAAoB,EAAE,GAAAA,EAAA,EAAA+B,IAAP,EAAfA,IAAI,GAAA7B,EAAA,cAAG,QAAQ,GAAAA,EAAA;cAG7B,IAAI,CAACG,WAAW,GAAG,IAAI7D,WAAW,CAAC;gBAAEuD,MAAM,EAAAA,MAAA;gBAAEP,WAAW,EAAAA;cAAA,CAAE,CAAC;cAE3D,qBAAM,IAAI,CAAC9B,eAAe,CAAC2B,KAAK,CAAC2C,MAAM,CAACrE,MAAM,CAAC,CAC7CS,IAAI,CAAC,UAAAoC,IAAI;gBACTyB,UAAU,GAAGzB,IAAI;cAClB,CAAC,CAAC,CACD3B,KAAK,CAAC,UAAAC,GAAG;gBACT,OAAOhB,GAAG,CAACgB,GAAG,CAAC;cAChB,CAAC,CAAC;;cANHW,EAAA,CAAAC,IAAA,EAMG;cACGgC,KAAK,GAAG;gBAAEX,KAAK,EAAEkB;cAAU,CAAE;cAC7BC,eAAe,GAAG,EAAE;cAGpBC,UAAU,GAAG9C,KAAK,CAAC2C,MAAM,CAACD,IAAI,IAAIA,IAAI;cAC5C,IAAII,UAAU,KAAK,QAAQ,IAAIA,UAAU,KAAK,KAAK,EAAE;gBACpDD,eAAe,CAACvB,IAAI,CAAC,IAAI,CAACyB,YAAY,CAACV,KAAK,CAAC,CAAC;;cAE/C,IAAIS,UAAU,KAAK,QAAQ,IAAIA,UAAU,KAAK,KAAK,EAAE;gBACpDD,eAAe,CAACvB,IAAI,CAAC,IAAI,CAAC0B,sBAAsB,CAACX,KAAK,CAAC,CAAC;;cAEzD;cACA;cACA;cACA9D,OAAO,CAAC0E,GAAG,CAACJ,eAAe,CAAC,CAC1B9D,IAAI,CAAC,UAAAoC,IAAI;gBACT,IAAI+B,cAAc,GAAyB,EAAE;gBAC7C;gBACA/B,IAAI,CAACgC,OAAO,CAAC,UAAAC,GAAG;kBACfF,cAAc,GAAAG,QAAA,CAAAA,QAAA,KAAQH,cAAc,GAAKE,GAAG,CAAE;gBAC/C,CAAC,CAAC;gBACF5E,GAAG,CAAC0E,cAAc,CAAC;cACpB,CAAC,CAAC,CACD1D,KAAK,CAAC,UAAAC,GAAG;gBAAI,OAAAhB,GAAG,CAACgB,GAAG,CAAC;cAAR,CAAQ,CAAC;;;;;KACxB,CAAC;EACH,CAAC;EAED;;;;;EAKQ1B,mCAAA,CAAAI,SAAA,CAAA4E,YAAY,GAApB,UACCV,KAAsC;IADvC,IAAApC,KAAA;IAGC,OAAO,IAAI1B,OAAO,CAAC,UAACC,GAAG,EAAEC,GAAG;MAC3BwB,KAAI,CAACe,WAAW,CAAC+B,YAAY,CAACV,KAAK,EAAE,UAAC5C,GAAG,EAAE0B,IAAI;QAC9C,IAAI1B,GAAG,EAAE,OAAOhB,GAAG,CAACgB,GAAG,CAAC;QACxB,IAAI,CAAC0B,IAAI,CAACmC,MAAM,EAAE,OAAO9E,GAAG,CAAC;UAAEmE,MAAM,EAAE;QAAI,CAAE,CAAC,CAAC,CAAC;QAChD,IAAMY,eAAe,GAAGpC,IAAI,CAACmC,MAAM,CAACE,GAAG,CAAC,UAAAJ,GAAG;UAC1C,IAAMK,KAAK,GAAGL,GAAG,CAACM,SAAS,GACxBN,GAAG,CAACM,SAAS,CAACF,GAAG,CAAC,UAAAJ,GAAG;YAAI,OAAA1F,aAAa,CAAC0F,GAAG,CAACO,WAAW,CAAC;UAA9B,CAA8B,CAAC,GACxDC,SAAS;UACZ,OAAO;YACNC,IAAI,EAAET,GAAG,CAAC7D,IAAI;YACduE,aAAa,EAAEL,KAAK;YACpBM,QAAQ,EAAE;cACTC,UAAU,EAAEZ,GAAG,CAACa,UAAU;cAC1BC,OAAO,EAAEvG,kBAAkB,CAACyF,GAAG,CAACe,OAAO;;WAExC;QACF,CAAC,CAAC;QACF,OAAO3F,GAAG,CAAC;UAAEmE,MAAM,EAAEY;QAAe,CAAE,CAAC;MACxC,CAAC,CAAC;IACH,CAAC,CAAC;EACH,CAAC;EAED;;;;;EAKQxF,mCAAA,CAAAI,SAAA,CAAA6E,sBAAsB,GAA9B,UACCX,KAAqC;IADtC,IAAApC,KAAA;IAGC,OAAO,IAAI1B,OAAO,CAAC,UAACC,GAAG,EAAEC,GAAG;MAC3BwB,KAAI,CAACe,WAAW,CAACgC,sBAAsB,CAACX,KAAK,EAAE,UAAC5C,GAAG,EAAE0B,IAAI;QACxD,IAAI1B,GAAG,EAAE,OAAOhB,GAAG,CAACgB,GAAG,CAAC;QACxB,IAAI0B,IAAI,CAACiD,gBAAgB,CAAChF,MAAM,KAAK,CAAC,EAAE;UACvC,OAAOZ,GAAG,CAAC;YAAE6F,MAAM,EAAE;UAAK,CAAE,CAAC;SAC7B,MAAM;UACN,OAAO7F,GAAG,CAAC;YAAE6F,MAAM,EAAE;UAAI,CAAE,CAAC;;MAE9B,CAAC,CAAC;IACH,CAAC,CAAC;EACH,CAAC;EAED;;;;;;EAMUtG,mCAAA,CAAAI,SAAA,CAAAmG,gBAAgB,GAA1B,UACCtE,KAA4B;IAD7B,IAAAC,KAAA;IAGC,OAAO,IAAI1B,OAAO,CAAC,UAAOC,GAAG,EAAEC,GAAG;MAAA,OAAAyB,SAAA,CAAAD,KAAA;;;;;;cACb,qBAAMjD,WAAW,CAAC6B,GAAG,EAAE;;cAArCsB,WAAW,GAAGoE,EAAA,CAAAlE,IAAA,EAAuB;cAC3C,IAAI,CAACF,WAAW,EAAE,sBAAO1B,GAAG,CAAC,gBAAgB,CAAC;cAE7C6B,EAAA,GAQG,IAAI,CAACC,OAAO,CAAA+D,gBADT,EAPN9D,EAAA,GAAAF,EAAA,cAOI,EAAE,GAAAA,EAAA,EANLG,EAAA,GAAAD,EAAA,CAAAE,MAAW,EAAXA,MAAM,GAAAD,EAAA,cAAG,EAAE,GAAAA,EAAA,EACXE,EAAA,GAAAH,EAAA,CAAAgE,yBAAiC,EAAjCA,yBAAyB,GAAA7D,EAAA,cAAG,KAAK,GAAAA,EAAA,EACjCE,EAAA,GAAAL,EAAA,CAAAI,QAGM,EAHNR,EAAA,GAAAS,EAAA,cAGI,EAAE,GAAAA,EAAA,EAFL4D,EAAA,GAAArE,EAAA,CAAAsE,YAAqC,EAAvBC,kBAAkB,GAAAF,EAAA,cAAG,EAAE,GAAAA,EAAA,EACrCG,EAAA,GAAAxE,EAAA,CAAAyE,WAAgC,EAAnBC,cAAc,GAAAF,EAAA,cAAG,EAAE,GAAAA,EAAA;cAInC;cAEA,IAAI,CAAC5D,WAAW,GAAG,IAAI7D,WAAW,CAAC;gBAAEuD,MAAM,EAAAA,MAAA;gBAAEP,WAAW,EAAAA;cAAA,CAAE,CAAC;cAE3D,qBAAM,IAAI,CAAC9B,eAAe,CAAC2B,KAAK,CAAC+E,QAAQ,CAACzG,MAAM,CAAC,CAC/CS,IAAI,CAAC,UAAAoC,IAAI;gBAAI,OAACyB,UAAU,GAAGzB,IAAI;cAAlB,CAAmB,CAAC,CACjC3B,KAAK,CAAC,UAAAC,GAAG;gBACT,OAAOhB,GAAG,CAACgB,GAAG,CAAC;cAChB,CAAC,CAAC;;cAJH8E,EAAA,CAAAlE,IAAA,EAIG;cAEGgC,KAAK,GAAG;gBAAEX,KAAK,EAAEkB;cAAU,CAAE;cAEnC,IACCrF,qBAAqB,CAACyC,KAAK,CAAC+E,QAAQ,CAAC,IACrC/E,KAAK,CAAC+E,QAAQ,CAACC,kBAAkB,EAChC;gBACD,IAAI,CAACR,yBAAyB,EAAE;kBAC/B,sBAAO/F,GAAG,CAAC,qDAAqD,CAAC;;gBAElE,IAAI,CAACuC,WAAW,CAACiE,oBAAoB,CAAC5C,KAAK,EAAE,UAAC5C,GAAG,EAAE0B,IAAI;kBACtD,IAAI1B,GAAG,EAAE,OAAOhB,GAAG,CAACgB,GAAG,CAAC;kBACxB,IAAMyF,KAAK,GAAG/D,IAAI,CAACgE,cAAc,CAAC3B,GAAG,CAAC,UAAA4B,SAAS;oBAC9C,OAAO;sBACNC,WAAW,EAAE3H,aAAa,CAAC0H,SAAS,CAACE,IAAI,CAAC3B,WAAW,CAAC;sBACtD4B,SAAS,EAAE5H,kBAAkB,CAACyH,SAAS,CAACE,IAAI,CAACE,SAAS,CAAC;sBACvDzB,QAAQ,EAAAV,QAAA,CAAAA,QAAA,KACJ3F,aAAa,CAAC0H,SAAS,EAAE,CAAC,IAAI,EAAE,MAAM,EAAE,MAAM,CAAC,CAAC;wBACnDK,IAAI,EAAE/H,aAAa,CAAC0H,SAAS,CAACE,IAAI,CAACI,IAAI;sBAAC;qBAEzC;kBACF,CAAC,CAAC;kBACFlH,GAAG,CAAC;oBAAEuG,QAAQ,EAAEG;kBAAK,CAAE,CAAC;gBACzB,CAAC,CAAC;eACF,MAAM,IACN1H,wBAAwB,CAACwC,KAAK,CAAC+E,QAAQ,CAAC,IACxC/E,KAAK,CAAC+E,QAAQ,CAACY,UAAU,EACxB;gBACKC,EAAA,GAGF5F,KAAK,CAAC+E,QAAkC,EAF3Cc,EAAA,GAAAD,EAAA,CAAAlB,YAAiC,EAAjCA,YAAY,GAAAmB,EAAA,cAAGlB,kBAAkB,GAAAkB,EAAA,EACjCC,EAAA,GAAAF,EAAA,CAAAf,WAAsC,EAAzBkB,QAAQ,GAAAD,EAAA,cAAGhB,cAAc,GAAAgB,EAAA;gBAIjCE,YAAY,GAAA3C,QAAA,CAAAA,QAAA,KACdhB,KAAK;kBACR4D,YAAY,EAAEvB,YAAY;kBAC1BwB,QAAQ,EAAEH;gBAAQ,EAClB;gBACD,IAAI,CAAC/E,WAAW,CAACmF,kBAAkB,CAACH,YAAY,EAAE,UAACvG,GAAG,EAAE0B,IAAI;kBAC3D,IAAI1B,GAAG,EAAE,OAAOhB,GAAG,CAACgB,GAAG,CAAC;kBACxB,IAAMyF,KAAK,GAAG/D,IAAI,CAACiF,WAAW,CAAC5C,GAAG,CAAC,UAAAJ,GAAG;oBACrC,OAAO;sBACNiC,WAAW,EAAE3H,aAAa,CAAC0F,GAAG,CAACkC,IAAI,CAAC3B,WAAW,CAAC;sBAChDI,QAAQ,EAAE;wBACTsC,eAAe,EAAEpG,KAAI,CAACqG,qBAAqB,CAC1ClD,GAAG,CAACkC,IAAI,CAACiB,eAAe,CACxB;wBACDC,UAAU,EAAEpD,GAAG,CAACqD;;qBAEjB;kBACF,CAAC,CAAC;kBACFjI,GAAG,CAAC;oBAAEuG,QAAQ,EAAEG;kBAAK,CAAE,CAAC;gBACzB,CAAC,CAAC;eACF,MAAM;gBACN,IAAI,CAAClE,WAAW,CAAC0F,WAAW,CAACrE,KAAK,EAAE,UAAC5C,GAAG,EAAE0B,IAAI;kBAC7C,IAAI1B,GAAG,EAAE,OAAOhB,GAAG,CAACgB,GAAG,CAAC;kBACxB,IAAMyF,KAAK,GAAG/D,IAAI,CAACwF,WAAW,CAACnD,GAAG,CAAC,UAAAoD,MAAM;oBACxC;oBACA,IAAMC,aAAa,GAAG,CACrB,OAAO,EACP,YAAY,EACZ,YAAY,EACZ,QAAQ,EACR,OAAO,EACP,UAAU,EACV,UAAU,EACV,WAAW,CACX;oBACD,IAAMC,cAAc,GAAGpJ,aAAa,CAACkJ,MAAM,EAAEC,aAAa,CAAC;oBAC3D,IAAID,MAAM,CAACG,QAAQ,EAAE;sBACpBD,cAAc,CAAC,UAAU,CAAC,GAAGF,MAAM,CAACG,QAAQ,CAACvD,GAAG,CAC/C,UAAAwD,OAAO;wBAAI,OAAAA,OAAO,CAACC,IAAI;sBAAZ,CAAY,CACvB;;oBAEF,OAAO;sBACN5B,WAAW,EAAE3H,aAAa,CAACkJ,MAAM,CAACjD,WAAW,CAAC;sBAC9C4B,SAAS,EAAE5H,kBAAkB,CAACiJ,MAAM,CAACpB,SAAS,CAAC;sBAC/C0B,QAAQ,EAAExJ,aAAa,CAACkJ,MAAM,CAACO,QAAQ,CAAC;sBACxCC,UAAU,EAAE1J,aAAa,CAACkJ,MAAM,EAAEC,aAAa,CAAC;sBAChD9C,QAAQ,EAAE;wBACTC,UAAU,EAAE4C,MAAM,CAAC3C,UAAU;wBAC7BwB,IAAI,EAAE/H,aAAa,CAACkJ,MAAM,CAAClB,IAAI;;qBAEhC;kBACF,CAAC,CAAC;kBACFlH,GAAG,CAAC;oBAAEuG,QAAQ,EAAEG;kBAAK,CAAE,CAAC;gBACzB,CAAC,CAAC;;;;;;KAEH,CAAC;EACH,CAAC;;EAEOnH,mCAAA,CAAAI,SAAA,CAAAmI,qBAAqB,GAA7B,UAA8BD,eAAuB;IACpD,OAAO,CAAC,EAAE,GAAGA,eAAe,EAAEgB,OAAO,CAAC,KAAK,EAAE,GAAG,CAAC;EAClD,CAAC;EACF,OAAAtJ,mCAAC;AAAD,CAAC,CApXgEb,mCAAmC"},"metadata":{},"sourceType":"module","externalDependencies":[]}